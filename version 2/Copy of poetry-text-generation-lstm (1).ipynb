{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of poetry-text-generation-lstm.ipynb","provenance":[{"file_id":"1mBOrQ5-kcDYFZMOzwXtXeq-e3S2-dAHa","timestamp":1613625464085}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"HmvA1YkFWVgA"},"source":["# Poetry with RNN\n","\n","Today, we will generate poems. I love reading and writing poetry, so I thought it would be fun to see what a machine can come up with rather than my own mind. I'm using the [Gutenberg Poetry Corpus by Allison Parris](https://github.com/aparrish/gutenberg-poetry-corpus).\n","\n","This is mostly a learning exercise and practice document for me. Hope you enjoy the read.\n","\n","#### Recurrent Neural Network (RNN)\n","A recurrent neural network is a network with loops in it, which allows previous outputs to be used as inputs to the current step while having a hidden state. The hidden state remembers some information about a sequence. It can be understood as multiple copies of the same network that each pass a message to the next network.\n","\n","For more details, [visit this Medium article by Suvro Banerjee](https://medium.com/explore-artificial-intelligence/an-introduction-to-recurrent-neural-networks-72c97bf0912).\n","\n","#### Long Short-Term Memory (LSTM) Networks\n","RNNs fail to understand the context behind input because they only remember things for short durations of time. Therefore once a lot of words are fed in, information gets lost and predictions are less reliable. This is because of the Vanishing Gradient problem: as more layers using the sigmoid activation function (or others) are added to neural networks, the gradients of the loss function approach 0. It becomes difficult to train layers. Read more about it [on Towards Data Science](https://towardsdatascience.com/the-vanishing-gradient-problem-69bf08b15484).\n","\n","We can use LSTM Networks, a version of a RNN, to fix this issue. With LSTMs, information flows through cell states, allowing for slight modification of information -- LSTMs can therefore selectively remember or forget things."]},{"cell_type":"markdown","metadata":{"id":"NxtqRf8uWVgO"},"source":["## Prepare Data"]},{"cell_type":"code","metadata":{"id":"bEHO0PNKWVgP","executionInfo":{"status":"aborted","timestamp":1615447775902,"user_tz":-570,"elapsed":306100,"user":{"displayName":"Kanchana Gunathilaka","photoUrl":"","userId":"08951501053370122904"}}},"source":["import json\n","import random\n","import numpy as np\n","import pandas as pd\n","\n","!pip install unicodedata2\n","!pip install regex\n","\n","all_lines = []\n","#for line in open(\"../input/sew-v1/sew_file_01_V1.txt\"):\n","#    print(line.strip())\n","#    all_lines.append(json.loads(line.strip()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kXxdEnvuWw77","executionInfo":{"status":"aborted","timestamp":1615447775903,"user_tz":-570,"elapsed":306090,"user":{"displayName":"Kanchana Gunathilaka","photoUrl":"","userId":"08951501053370122904"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yiWK1ls5WVgP","executionInfo":{"status":"aborted","timestamp":1615447775904,"user_tz":-570,"elapsed":306083,"user":{"displayName":"Kanchana Gunathilaka","photoUrl":"","userId":"08951501053370122904"}}},"source":["#corpus = \"\\n\".join([line['s'] for line in random.sample(all_lines, 1000)])\n","#corpus = open(\"../input/sew-v1/sew_file_01_V1.txt\")\n","f = open(\"/content/drive/MyDrive/Colab Notebooks/sinhala_data_combined.txt\", \"r\", encoding=\"utf-8\")\n","#print(f.read())\n","#corpus = \"\\n\".join([line['s'] for line in all_lines])\n","corpus = f.read()\n","print(corpus)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zj63flILWVgR"},"source":["## Aside: Markov chain text generation\n","\n","Markov chains generate sentences based on recombination of elements of known sentences: it analyzes the words and the probability of occurence of two consecutive words. The generation is randomized and based on the probability of each words.\n","\n","Let's generate a poem with this method, and then continue with our RNN method to see how they compare."]},{"cell_type":"code","metadata":{"id":"mgn3riRuWVgS","executionInfo":{"status":"aborted","timestamp":1615447775904,"user_tz":-570,"elapsed":306074,"user":{"displayName":"Kanchana Gunathilaka","photoUrl":"","userId":"08951501053370122904"}}},"source":["#import markovify"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k5EsyL8fWVgS","executionInfo":{"status":"aborted","timestamp":1615447775905,"user_tz":-570,"elapsed":306068,"user":{"displayName":"Kanchana Gunathilaka","photoUrl":"","userId":"08951501053370122904"}}},"source":["#model = markovify.NewlineText(corpus)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xc-cqKGEWVgS","executionInfo":{"status":"aborted","timestamp":1615447775906,"user_tz":-570,"elapsed":306064,"user":{"displayName":"Kanchana Gunathilaka","photoUrl":"","userId":"08951501053370122904"}}},"source":["#for i in range(5):\n","#    print()\n","#    for i in range(random.randrange(1, 4)):\n","#        print(model.make_short_sentence(30))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3GNW_7c-WVgT"},"source":["## Character-Level LSTM Text Generation\n","\n","#### Import Libraries"]},{"cell_type":"code","metadata":{"id":"ySQgo1IEWVgT","executionInfo":{"status":"aborted","timestamp":1615447775906,"user_tz":-570,"elapsed":306059,"user":{"displayName":"Kanchana Gunathilaka","photoUrl":"","userId":"08951501053370122904"}}},"source":["from keras.layers import LSTM, Dense, Dropout, Flatten\n","from keras.callbacks import LambdaCallback\n","from keras.models import Sequential\n","from keras.optimizers import RMSprop\n","from keras.utils import np_utils"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mf-akGvsWVgU"},"source":["#### Prepare Text"]},{"cell_type":"code","metadata":{"id":"eQAuP4NzWVgU","executionInfo":{"status":"aborted","timestamp":1615447775907,"user_tz":-570,"elapsed":306054,"user":{"displayName":"Kanchana Gunathilaka","photoUrl":"","userId":"08951501053370122904"}}},"source":["# Lowercase all text\n","text = corpus.lower()\n","\n","#chars = list(set(text))\n","#print(chars)\n","#char_indices = dict((c, i) for i, c in enumerate(chars))\n","#print(char_indices)\n","#indices_char = dict((i, c) for i, c in enumerate(chars))\n","#print(indices_char)\n","\n","#vocab_size = len(chars)\n","#print('Vocabulary size: {}'.format(vocab_size))\n","\n","\n","import unicodedata \n","\n","liste=[]\n","#s = u\"ɔ̃w̃ɔtɨ\"\n","s=text\n","comb=False\n","prec=u\"\"\n","for char in s:\n","    if unicodedata.combining(char):\n","        liste.append(prec+char)\n","        #print('unicodedata.combining'+prec+char)\n","        prec=\"\"\n","    #elif unicodedata.bidirectional(char):\n","        #print(prec+char)\n","    else:\n","        liste.append(prec)\n","        prec=char\n","        #print(prec)\n","liste.append(prec)\n","#print (liste)\n","#diacritics_dictionary=dict(zip(liste,range(len(liste))))\n","#print (diacritics_dictionary)\n","\n","import regex\n","reg_output= regex.findall(r'\\X', text)\n","#print(reg_output)\n","duplicates_removed = list(dict.fromkeys(reg_output))\n","#print (duplicates_removed)\n","\n","chars = duplicates_removed\n","print (chars)\n","#chars.pop(3)\n","char_indices = dict((c, i) for i, c in enumerate(duplicates_removed))\n","print(char_indices)\n","indices_char = dict((i, c) for i, c in enumerate(duplicates_removed))\n","print(indices_char)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gkjN9fqoWVgU"},"source":["#### Prepare Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nMhZFX14WVgV","executionInfo":{"status":"ok","timestamp":1615447478222,"user_tz":-570,"elapsed":19431,"user":{"displayName":"Kanchana Gunathilaka","photoUrl":"","userId":"08951501053370122904"}},"outputId":"8e974ff1-164f-4878-9d0d-159de190066c"},"source":["# Data preparation\n","X = [] # training array\n","Y = [] # target array\n","\n","length = len(reg_output)\n","seq_length = 25 # number of characters to consider before predicting a character\n","\n","# Iterate over length of text and create sequences stored in X, true values stored in Y\n","# true values being which character would actually come after sequence stored in X\n","for i in range(0, length - seq_length, 1):\n","    sequence = reg_output[i:i + seq_length]\n","    \n","    label = reg_output[i + seq_length]\n","    \n","    if label in char_indices:\n","      #print('sequence')\n","      #print(''.join(map(str, sequence)))  \n","      #print('label')\n","      #print(''.join(map(str, label)))\n","      Y.append(char_indices[label])\n","      X_arrry= []\n","      for char in sequence:\n","        if char in char_indices:\n","          X_arrry.append(char_indices[char])\n","      X.append(X_arrry)\n","\n","print('Number of sequences X: {}'.format(len(X)))\n","print('Number of sequences Y {}'.format(len(Y)))\n","#print(X)\n","#print(Y)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Number of sequences X: 1060710\n","Number of sequences Y 1060710\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZF5VUT5WVgX","executionInfo":{"status":"ok","timestamp":1615448393229,"user_tz":-570,"elapsed":6958,"user":{"displayName":"Kanchana Gunathilaka","photoUrl":"","userId":"08951501053370122904"}},"outputId":"4b9de29d-e693-4fa5-8cc7-c57eab01a3d1"},"source":["# Reshape dimensions\n","X_new = np.reshape(X, (len(X), seq_length, 1))\n","#print(X_new)\n","# Scale values\n","X_new = X_new/float(len(chars))\n","print(X_new.shape)\n","# One-hot encode Y to remove ordinal relationships\n","Y_new = np_utils.to_categorical(Y)\n","print(Y_new)\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["(1060710, 25, 1)\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3eiXsFwFWVgX"},"source":["#### Create Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"kbCVsX8TWVgY","executionInfo":{"status":"error","timestamp":1615447775907,"user_tz":-570,"elapsed":317096,"user":{"displayName":"Kanchana Gunathilaka","photoUrl":"","userId":"08951501053370122904"}},"outputId":"8bc8f92e-fb7a-4ef1-edf0-788a5aeb8b3a"},"source":["model = Sequential()\n","# Add LSTM layer to compute output using 150 LSTM units\n","model.add(LSTM(150, input_shape = (X_new.shape[1], X_new.shape[2]), return_sequences = True))\n","\n","# Add regularization layer to prevent overfitting.\n","# Dropout ignores randomly selected neurons during training (\"dropped out\").\n","# Ultimately, network becomes less sensitive to specific weights of neurons --> network is better at generalization.\n","model.add(Dropout(0.1))\n","\n","model.add(Flatten())\n","# Dense layer with softmax activation function to approximate probability distribution of next best word\n","model.add(Dense(Y_new.shape[1], activation = 'softmax'))\n","\n","# Compile model to configure learning process\n","# Categorical crossentropy: an example can only belong to one class\n","# Adam optimization algorithm updates a learning rate for each network weight iteratively as learning unfolds\n","model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n","\n","# Use 1 epoch for sake of computational time\n","model.fit(X_new, Y_new, epochs = 1, verbose = 1)\n","model.save(\"model.h5\")"],"execution_count":12,"outputs":[{"output_type":"stream","text":[" 4421/33148 [===>..........................] - ETA: 31:36 - loss: 4.3175"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-109fbc8017f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Use 1 epoch for sake of computational time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"yOeCOGZsWVgY"},"source":["#### Generate Text"]},{"cell_type":"code","metadata":{"id":"4qy39UdyeQtn","executionInfo":{"status":"aborted","timestamp":1615447775891,"user_tz":-570,"elapsed":317075,"user":{"displayName":"Kanchana Gunathilaka","photoUrl":"","userId":"08951501053370122904"}}},"source":["0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dSw5RHmWWVgZ","executionInfo":{"status":"aborted","timestamp":1615447775893,"user_tz":-570,"elapsed":317070,"user":{"displayName":"Kanchana Gunathilaka","photoUrl":"","userId":"08951501053370122904"}}},"source":["# Random start\n","start = np.random.randint(0, len(X)-1)\n","print(start)\n","string_mapped = list(X[start])\n","print('string_mapped')\n","print(string_mapped)\n","full_string = [indices_char[value] for value in string_mapped]\n","print('full_string')\n","print(full_string)\n","# Generate text\n","for i in range(400):\n","    x = np.reshape(string_mapped, (1, len(string_mapped), 1))\n","    x = x / float(len(chars))\n","    #print(x)\n","    pred_index = np.argmax(model.predict(x, verbose = 0))\n","    print(pred_index)\n","    seq = [indices_char[value] for value in string_mapped]\n","    #print(seq)\n","    full_string.append(indices_char[pred_index])\n","    #print(full_string)\n","    \n","    string_mapped.append(pred_index)\n","    print(string_mapped)\n","    string_mapped = string_mapped[1:len(string_mapped)]\n","    print(string_mapped)\n","\n","print(full_string)\n","print(string_mapped)   \n","# Combine text\n","newtext = ''\n","for char in full_string:\n","    newtext = newtext + char\n","\n","print(newtext)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5xaTu9DmWVgZ"},"source":["## Predicting Next Words"]},{"cell_type":"code","metadata":{"id":"0vNZPojHWVga","executionInfo":{"status":"aborted","timestamp":1615447775895,"user_tz":-570,"elapsed":317066,"user":{"displayName":"Kanchana Gunathilaka","photoUrl":"","userId":"08951501053370122904"}}},"source":["import keras.utils as ku\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.layers import Embedding\n","\n","# Lowercase all text\n","text = corpus.lower()\n","text = text.split('\\n')\n","\n","# Create Tokenizer object to convert words to sequences of integers\n","tokenizer = Tokenizer(num_words = None, filters = '#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n', lower = False)\n","\n","# Train tokenizer to the texts\n","tokenizer.fit_on_texts(text)\n","total_words = len(tokenizer.word_index) + 1\n","\n","# Convert list of strings into flat dataset of sequences of tokens\n","sequences = []\n","for line in text:\n","    token_list = tokenizer.texts_to_sequences([line])[0]\n","    for i in range(1, len(token_list)):\n","        n_gram_sequence = token_list[:i+1]\n","        sequences.append(n_gram_sequence)\n","\n","# Pad sequences to ensure equal lengths\n","max_seq_len = max([len(x) for x in sequences])\n","sequences = np.array(pad_sequences(sequences, maxlen = max_seq_len, padding = 'pre'))\n","\n","# Create n-grams sequence predictors and labels\n","predictors, label = sequences[:, :-1], sequences[:, -1]\n","label = ku.to_categorical(label, num_classes = total_words)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LXB5ATFsWVgb"},"source":["#### Create Model"]},{"cell_type":"code","metadata":{"id":"9Dv_n6-bWVgc","executionInfo":{"status":"aborted","timestamp":1615447775896,"user_tz":-570,"elapsed":317062,"user":{"displayName":"Kanchana Gunathilaka","photoUrl":"","userId":"08951501053370122904"}}},"source":["# Input layer takes sequence of words as input\n","input_len = max_seq_len - 1\n","model = Sequential()\n","model.add(Embedding(total_words, 10, input_length = input_len))\n","model.add(LSTM(150))\n","model.add(Dropout(0.1))\n","model.add(Dense(total_words, activation = 'softmax'))\n","model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n","\n","# Use 100 epoch for efficacy\n","model.fit(predictors, label, epochs = 100, verbose = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJloG6xWWVgc","executionInfo":{"status":"aborted","timestamp":1615447775897,"user_tz":-570,"elapsed":317057,"user":{"displayName":"Kanchana Gunathilaka","photoUrl":"","userId":"08951501053370122904"}}},"source":["# Function to generate line\n","def generate_line(text, next_words, max_seq_len, model):\n","    for j in range(next_words):\n","        token_list = tokenizer.texts_to_sequences([text])[0]\n","        token_list = pad_sequences([token_list], maxlen = max_seq_len - 1, padding = 'pre')\n","        predicted = model.predict_classes(token_list, verbose = 0)\n","        \n","        output_word = ''\n","        for word, index in tokenizer.word_index.items():\n","            if index == predicted:\n","                output_word = word\n","                break\n","        text += ' ' + output_word\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7accXGU8WVgd","executionInfo":{"status":"aborted","timestamp":1615447775898,"user_tz":-570,"elapsed":317052,"user":{"displayName":"Kanchana Gunathilaka","photoUrl":"","userId":"08951501053370122904"}}},"source":["generate_line(\"ආදර\", 5, max_seq_len, model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-nu7RVUVWVgd","executionInfo":{"status":"aborted","timestamp":1615447775899,"user_tz":-570,"elapsed":317047,"user":{"displayName":"Kanchana Gunathilaka","photoUrl":"","userId":"08951501053370122904"}}},"source":["generate_line(\"කතා\", 5, max_seq_len, model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JX58iaZ6WVgd"},"source":["##### Thank you!"]}]}